# Скрапинг данных с сайта "Российский новый университет"<br/>https://rosnou.ru/institutes/'


 ## Алгоритм main.py:
- Нахожу все 8 институтов. 
- из каждого возьму Название, ссылку
- прохожу по ссылке в каждый университет
- получаю наименование специальности
- получаю имя универа
- получаю, если есть стоимость и количество бюджетных мест
- данные запишу в json & csv (Прилично)

## Алгоритм main2.py
- получаю все карточки универов
- получаю из них ссылки на каждый универ
- делаю запрос к каждому универу и получаю Направления обучения, Наименование института, стоимость, количество бюджетных мест (если есть)
- записываю в csv

### Использую в проекте паузу между реквестами, сохраню промежуточные страницы (это можно не делать, но мне нужно для практики)
<br/>
<br/>

## **Особенность проекта:** <br/>
### Поиск нужных зацепок в коде решаю двумя способами. <br/>
В первом-**main.py** использую (из нового): 
- find_next(первое совпадение в ближайшем следующем элементе), 
- parent(прогон по коду вверх к ближайшему элементу), 
- модуль регулярного выражения string=re.compile("Бюджетных мест")),
- previous_sibling (предыдущий элемент-родственник на одном уровне)

В втором-**main2.py**
Использую 
- "Приличный" метод записи в csv (не как раньше, одним скриптом заголовки, а потом  другим скриптом информацию)

**так же использую:**
- " ".join(institute_dirty.split()) # классно!
- replace("\n", "")
- try, 
- except

